{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ['dow', 'hour', 'month'\n",
    "           , 'timediff', 'event'\n",
    "          ]\n",
    "feat_context = {}\n",
    "for feat in context:\n",
    "    feat_context[feat] = [feat+'_'+str(i+1) for i in range(20)]\n",
    "x_item = ['item_'+str(i+1) for i in range(19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pth = Path('../data/CRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(data_pth/'train_tu.csv')\n",
    "df_val = pd.read_csv(data_pth/'valid_tu.csv')\n",
    "df_test = pd.read_csv(data_pth/'test_tu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_uniq = np.unique(df_train[['item_19', 'item_20']].values.astype(int))\n",
    "index = np.argwhere(item_uniq==-1)\n",
    "item_uniq = np.delete(item_uniq, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_val.loc[df_val['item_20'].isin(item_uniq)].reset_index(drop=True)\n",
    "df_test = df_test.loc[df_test['item_20'].isin(item_uniq)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item2index = {-1:0, 'UNK':1}\n",
    "items = [-1, 'UNK']\n",
    "for item in item_uniq:\n",
    "    item2index[item] = len(items)\n",
    "    items.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class recDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.n_feat = len(context)\n",
    "        self.df = df\n",
    "        self.x_item = df[x_item].values\n",
    "        self.y = df['item_20'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = np.array([item2index.get(k, item2index[\"UNK\"]) for k in self.x_item[idx]])\n",
    "        y = item2index.get(self.y[idx], item2index[\"UNK\"])\n",
    "        feats = {}\n",
    "        for feat in feat_context:\n",
    "            feats[feat] = (self.df.loc[idx, feat_context[feat]].values+1).astype(int)\n",
    "        return x, y, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = recDataset(df_train)\n",
    "val_ds = recDataset(df_val)\n",
    "test_ds = recDataset(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(GRUModel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.month_embed = nn.Embedding(13, 2, padding_idx=0)\n",
    "        self.hour_embed = nn.Embedding(25, 2, padding_idx=0)\n",
    "        self.dow_embed = nn.Embedding(8, 2, padding_idx=0)\n",
    "        self.timediff_embed = nn.Embedding(21, 2, padding_idx=0)\n",
    "        self.event_embed = nn.Embedding(3, 2, padding_idx=0)\n",
    "        \n",
    "        self.context_transform = nn.Linear(10, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim+10, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim+10, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, feats):\n",
    "        x = self.embeddings(x)\n",
    "        month = self.month_embed(feats['month'].long())\n",
    "        hour = self.hour_embed(feats['hour'].long())\n",
    "        dow = self.dow_embed(feats['dow'].long())\n",
    "        timediff = self.timediff_embed(feats['timediff'].long())\n",
    "        event = self.event_embed(feats['event'].long())\n",
    "        context = torch.cat((month[:,:-1,:], hour[:,:-1,:], dow[:,:-1,:], \n",
    "                             timediff[:,:-1,:], event[:,:-1,:]), 2)\n",
    "        x = x*(self.context_transform(context))\n",
    "        x = torch.cat((x, context), 2)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        out, ht = self.gru(x)\n",
    "        final = ht[-1]\n",
    "        y_context = torch.cat((month[:,-1,:], hour[:,-1,:], dow[:,-1,:], \n",
    "                             timediff[:,-1,:], event[:,-1,:]), 1)\n",
    "        final = final*(self.context_transform(y_context))\n",
    "        final = torch.cat((final, y_context), 1)     \n",
    "        return self.linear(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3.1 Hyper-parameters. We fixed the size of item embedding vector and the size of RNN hidden state to 100. For optimization of the loss function in Equation 5, we use the Adam algorithm with squared root decay of learning rate from 0.01 to 0.001. For all models, the batch size was set 256 and number of training iterations to 10,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pth = Path('../model/CRNN')\n",
    "p = model_pth/'best_model.pth'\n",
    "best_recall = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, optimizer, train_dl, val_dl, best_recall, epochs=10):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, feats in tqdm_notebook(train_dl):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            for key, value in feats.items():\n",
    "                feats[key] = value.cuda()\n",
    "            y_pred = model(x, feats)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_recall = val_metrics(model, val_dl)\n",
    "        if val_recall>best_recall:\n",
    "            best_recall = val_recall\n",
    "            save_model(model, p)\n",
    "        if i%5==1:\n",
    "            print(\"train loss %.3f val loss %.3f and val recall@10 %.3f\" % (sum_loss/total, val_loss, val_recall))\n",
    "    return best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    recall = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, y, feats in tqdm_notebook(valid_dl):\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        for key, value in feats.items():\n",
    "            feats[key] = value.cuda()\n",
    "        y_hat = model(x, feats)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        _, indices = torch.topk(y_hat, k=10, dim=1)\n",
    "        for i, k in enumerate(y):\n",
    "            if k in indices[i]:\n",
    "                recall += 1\n",
    "    return sum_loss/total, recall/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUModel(len(item2index), 100, 100).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3b21c811944e85adaeae04e1f74f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fd12a5594b4135a312821b27d05e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_recall = train_epocs(model, optimizer, train_dl, val_dl, best_recall, epochs=1)\n",
    "save_model(model, model_pth/'model2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2388238424693986"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_recall = train_epocs(model, optimizer, train_dl, val_dl, best_recall, epochs=20)\n",
    "save_model(model, model_pth/'model20.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42030335284725917"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a04f19028a4815bc26caa36f297629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "update_optimizer(optimizer, lr=0.001)\n",
    "best_recall = train_epocs(model, optimizer, train_dl, val_dl, best_recall, epochs=20)\n",
    "save_model(model, model_pth/'model40.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711e4dfcf3d34556b96e87bc589cfa72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "load_model(model, model_pth/'model40.pth')\n",
    "recall_40 = val_metrics(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada51a2b6e684bf2ba57a80c59f8005e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "load_model(model, model_pth/'best_model.pth')\n",
    "recall_best = val_metrics(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4048, 0.4231\n"
     ]
    }
   ],
   "source": [
    "print(f'{recall_40[1]:.4f}, {recall_best[1]:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Salk)",
   "language": "python",
   "name": "salk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
